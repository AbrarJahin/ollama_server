services:
  ollama:
    image: ollama/ollama:0.13.5
    container_name: ollama
    restart: unless-stopped

    ports:
      - "11434:11434"

    # Keep all models/data beside your code (e.g., on D:\...)
    volumes:
      - ./ollama_data:/root/.ollama

    # NVIDIA GPU support (your Compose requires a LIST of MAPPINGS)
    gpus:
      - driver: nvidia
        count: all
        capabilities: [gpu]

    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    # Override ENTRYPOINT ("ollama") so we can run a shell script
    entrypoint:
      - /bin/sh
      - -lc

    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

    # IMPORTANT: use $$ to prevent Compose from substituting $MARKER and $pid
    command: |
      MARKER=/root/.ollama/.models_initialized

      ollama serve &
      pid=$$!

      sleep 2

      if [ ! -f "$$MARKER" ]; then
        echo "First run: pulling default models..."
        ollama pull qwen2.5:14b-instruct
        ollama pull bge-m3
        touch "$$MARKER"
      else
        echo "Models already initialized; skipping pulls."
      fi

      wait $$pid
