services:
  ollama:
    image: ollama/ollama:0.13.5
    container_name: ollama
    restart: unless-stopped

    ports:
      - "11434:11434"

    volumes:
      - ./ollama_data:/root/.ollama

    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    healthcheck:
      test: ["CMD", "bash", "-lc", "ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

    command: >
      sh -c "
        MARKER=/root/.ollama/.models_initialized;
        ollama serve &
        pid=$!;
        sleep 2;

        if [ ! -f \"$MARKER\" ]; then
          echo 'First run: pulling default models...';
          ollama pull qwen2.5:14b-instruct;
          ollama pull bge-m3;
          touch \"$MARKER\";
        else
          echo 'Models already initialized; skipping pulls.';
        fi;

        wait $pid
      "
